{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophieSchau/MRF_demo_ISMRM2022/blob/main/MRF_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MRF processing demo\n",
        "This notebook will demonstrate the processing pipeline used in the abstract *Toward a 1-minute high-resolution brain exam - MR Fingerprinting with ML-synthesized contrasts and fast reconstruction* presented at the 2022 ISMRM Annual meeting in London (program number 53).\n",
        "\n",
        "Before you start, Make sure you have a GPU enabled runtime (*Runtime->Change runtime type->set hardware accelerator to GPU*).\n",
        "\n",
        "*This demo takes approximately 25 min to run(Reconstruction is 15-20min). So, please start running the cells before you start reading!*\n",
        "\n"
      ],
      "metadata": {
        "id": "eoHHhN-eqtmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "This project is aimed at translating highly undrsampled MRF to a clinically feasible tool, by building a robust reconstruction pipeline that is portable between different compute systems (research lab, hospital, high performance computing cluster, collaborators, etc...). To achieve this these core objectives were set:\n",
        "\n",
        "- The pipeline should run smoothly on multiple systems.\n",
        "- The pipeline should be easy to upgrade when the sequence, the reconstruction method, or the synthesis method is changed.\n",
        "- The pipeline should be able to provide an image to send back to the scanner within 5 min.\n",
        "- The pipeline should be able to send a series of images to PACS within ~30min.\n",
        "- The pipeline should run on hardware available in clinical settings (for now, this means an 11GB GPU).\n",
        "\n",
        "This modular MRF processing pipeline includes 4 steps:\n",
        "\n",
        "1.   Read raw scan data and metadata(In the demo this step is replaced with downloading a demo dataset)\n",
        "2.   Reconstruct and get coil compression from calibration scan\n",
        "3.   Reconstruct MRF (fast subspace basis reconstruction)\n",
        "4.   Synthesize clinical contrasts\n",
        "\n",
        "Each step will be demonstrated here, and documentation on how to run the equivalent Docker containers on your own machine will be explained in a final section of this document.\n"
      ],
      "metadata": {
        "id": "HD0Rb98Rj7yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data and code download \n",
        "*Run the next code block before reading this! The data takes around 5 minutes to download*\n",
        "\n",
        "For this demo we have prepared a dataset consisting of five files:\n",
        "1. `mrf_raw.npy` <- contains MRF kspace data\n",
        "2. `calib_raw.npy` <- contains calibration GRE kspace data\n",
        "3. `calib_nse.npy` <- contains noise measurement from the calibration GRE\n",
        "4. `traj_grp16_inacc2.mat` <- contains the trajectory coordinates for the MRF\n",
        "5. `subspace_basis_grp16.mat` <- contains the temporal basis components for the MRF\n",
        "\n",
        "\n",
        "`mrf_raw.npy`, `calib_raw.npy`, and `calib_nse.npy` have been generated from ScanArchive files, which is the raw data output format used for MRI scanners by GE Healthcare. The conversion was done using containerized code provided by GE Healthcare. Since containers cannot easily be executed in Google Colab we skipped this step in the demo. However, if you want to run the conversion on your own system, you can run the containerized version on your own computer as explained in the final section of this demo.\n",
        "\n",
        "*If your data hasn't downloaded yet, please sing happy birthday to yourself to pass the time, your birthday is soon/was recently anyway!*"
      ],
      "metadata": {
        "id": "6dsuxgGZ9B-V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRlFFm41N3nx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "mkdir tmp\n",
        "cd tmp\n",
        "wget -q -O data.zip -L https://stanfordmedicine.box.com/shared/static/61tx7yzaxrcw4ktrlpebwn1tom5urx6s\n",
        "unzip -q data.zip\n",
        "cd /content/\n",
        "mv /content/tmp/MRF_Demo_ISMRM2022 /content/data\n",
        "rm -rf tmp\n",
        "mkdir /content/result\n",
        "mkdir /content/result/synth/\n",
        "\n",
        "git clone -q https://github.com/SophieSchau/MRF_demo_ISMRM2022.git\n",
        "pip install -q git+https://github.com/mikgroup/sigpy.git@master"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconstruct and get coil compression from calibration scan\n",
        "In this section we are going to use the raw k-space data from the calibration scan together with the noise measurment to perform coil whitening and [RoVir](https://doi.org/10.1002/mrm.28706) compression to remove any signal outside the central 256x256x256 mm field of view (where the MRF is to be reconstructed).\n",
        "\n",
        "Each section of the pipeline is built up in its own folder in the repo, and has a `main.py` function that will perform the pipeline step. The idea is that if we change for example the calibration scan to a one with a different trajectory, all we need to do is update the data loader but the top level execution of the pipeline remains unchanged.\n",
        "\n",
        "This example shows how we ran the calibration for the data shown at ISMRM 2022. The flags used here are:\n",
        "- `--ksp` which sets the path to the raw calibration data\n",
        "- `--nse` which sets the path to the noise measurement\n",
        "-  `--ccm` which sets the location of the resulting coil compression matrix to use for the MRF acquisition\n",
        "- `--rci` which we only include for demo purposes as it saves the rovir compressed calibration images so we can see the effect rovir has on the signal \n",
        "- `--nrc` sets the number of RoVir coils to compress down to (original number of coils in this case is 48)\n",
        "- `--nsv` how many virtual coils to keep after svd compression (after RoVir).\n",
        "\n",
        "You can also see all available flags and what they do by calling `main.py -h`.\n",
        "\n",
        "Feel free to play around with different numbers of RoVir and SVD coils and see how that affects the signal in outside the center of the FOV. For example, not using RoVir at all (setting `--nrc` to 48) results in large signal originating in the neck outside the field-of-view."
      ],
      "metadata": {
        "id": "Kg3dimdu6vGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/MRF_demo_ISMRM2022/src/01_calib/\n",
        "\n",
        "python3 main.py --ksp /content/data/calib_raw.npy \\\n",
        "                --nse /content/data/calib_nse.npy \\\n",
        "                --ccm /content/result/ccm.npy \\\n",
        "                --rci /content/result/rovir_recon.npy \\\n",
        "                --nrc 40 --nsv 10 \\"
      ],
      "metadata": {
        "id": "44XNYGY1mlxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at the results of the calibration!\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "rovir_im = np.sum(np.abs(np.load('/content/result/rovir_recon.npy'))**2,axis=3) # sum of squares accross coils\n",
        "\n",
        "for axis in [0,1,2]:\n",
        "  fig, ax = plt.subplots()\n",
        "  rect = patches.Rectangle((16, 16), 32, 32, linewidth=1, edgecolor='r', facecolor='none') # this rectangle defines the MRF field of view\n",
        "  if axis is 0:\n",
        "    ax.imshow(np.flipud(np.abs(rovir_im[:,:,32])), cmap='gray')\n",
        "  elif axis is 1:\n",
        "    ax.imshow(np.flipud(np.abs(rovir_im[:,32,:])), cmap='gray')\n",
        "  elif axis is 2:\n",
        "    ax.imshow(np.flipud(np.abs(rovir_im[32,:,:])), cmap='gray')\n",
        "  ax.add_patch(rect)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "9NxmnU0bDndk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRF Reconstruction\n",
        "*Again, we recommend running the next cell before reading through this as we have noticed that the reconstruction is much slower on Colab than when we run it locally (takes about 7 minutes locally and 15-20 min on Colab). Probably due to inefficient CPU to GPU data transfer.*\n",
        "\n",
        "This is the main part of the reconstruction pipeline, where the MRF data is actually reconstructed into subspace basis maps.\n",
        "\n",
        "Similarly, to the previous section , we move into the folder in the repository containing the `main.py` function for this part of the pipeline and then run it with a number of flags to define the reconstruction we want to run:\n",
        "- `-c` reconstruction type (-c this means conjugate gradient, but we have also implemented -p, which is a [preconditioned locally-low-rank regularized reconstruction](https://submissions.mirasmart.com/ISMRM2022/itinerary/Files/PDFFiles/3483.html) that we used as ground truth in this project (this takes a long time to run so is omitted in this demo).\n",
        "- `--phi` path to subspace basis\n",
        "- `--trj` path to trajectory\n",
        "- `--ksp` path to raw k-space data\n",
        "- `--ccm` path to coil compression matrix (generated in previous section)\n",
        "- `--res` path to where the resulting recosntruction should be saved\n",
        "- `--yfv` run auto-FOV algorithm to center the image (this uses more RAM than Colab can manage so we will skip this step since the subject is inside the FOV already).\n",
        "- `--mtx` matrix size\n",
        "- `--ptt` number of points to remove from beginning of readout (this adds stability to the reconstruction)\n",
        "- `--rnk` how many subspace coefficients to use\n",
        "- `--mit` number of iterations\n",
        "- `--nco` number of virtual coils to use\n",
        "\n",
        "Again, you can see a full list of flags and changeable settings by running `main.py -h`."
      ],
      "metadata": {
        "id": "TRGo4HfYCXBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t59cQ2mrOsJu"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/MRF_demo_ISMRM2022/src/02_recon/\n",
        "\n",
        "python3 main.py -c --phi /content/data/subspace_basis_grp16.mat \\\n",
        "                   --trj /content/data/traj_grp16_inacc2.mat \\\n",
        "                   --ksp /content/data/mrf_raw.npy \\\n",
        "                   --ccm /content/result/ccm.npy \\\n",
        "                   --res /content/result/fast.npy \\\n",
        "                   --yfv False \\\n",
        "                   --mtx 256 --ptt 10 --rnk 3 --mit 40 --nco 3\n",
        "                   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast = np.load('/content/result/fast.npy')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 30]\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(np.rot90(np.flipud(np.abs(fast[:,:,150,0]))),cmap='gray', vmin=0, vmax=0.002)\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(np.rot90(np.flipud(np.abs(fast[:,:,150,1]))),cmap='gray', vmin=0, vmax=0.001)\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(np.rot90(np.flipud(np.abs(fast[:,:,150,2]))),cmap='gray', vmin=0, vmax=0.0004)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nxhARm_xPrSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrast synthesis\n",
        "*Did you finish the recon? Good job! Now it's just the easy part left, contrast synthesis! (this part takes about 3 min)*\n",
        "\n",
        "For this part of the pipeline we again change folder and run the `main.py` function (you have probalbly gotten the gist now!). This function takes the recon from the previous step and uses it as input in a neural network that has been trained on 10 healthy volunteers to generate contrast weighted images.\n",
        "\n",
        "The flags used in this step are:\n",
        "- `--inp` the input data (subspace basis maps from the previous step)\n",
        "- `--wgt` weights for the neural network. Note, the one we use here is for data with the settings for the recon above, if yu use different settings yu might get suboptimal results.\n",
        "- `--sth` in which folder to save the synthesized images (folder must exist already)\n",
        "- `--idx` indecies of contrasts to synthesize. They follow this mapping: \n",
        "\n",
        "  0. T1-weighted Cube\n",
        "  1. T1-weighted MPRAGE\n",
        "  2. T2-weighted Cube\n",
        "  3. T2-weighted FLAIR Cube\n",
        "  4. T2-weighted Double Inversion Recovery Cube"
      ],
      "metadata": {
        "id": "_Tn89ODDCmpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/MRF_demo_ISMRM2022/src/03_synth/\n",
        "\n",
        "python3 main.py  --inp /content/result/fast.npy \\\n",
        "                 --wgt /content/MRF_demo_ISMRM2022/src/03_synth/checkpoints/v1_InitCG/800_net_G.pth \\\n",
        "                 --sth /content/result/synth \\\n",
        "                 --idx 0 1 2 3 4"
      ],
      "metadata": {
        "id": "xNY7aVzAkqOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast = np.load('/content/result/fast.npy')\n",
        "\n",
        "for contrast in ['t1mprage', 't1w', 't2w', 't2flair', 'dir']:\n",
        "  synth = np.load('/content/result/synth/' + contrast + '.npy')\n",
        "  plt.rcParams['figure.figsize'] = [25, 15]\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.imshow(np.rot90(np.flipud(np.abs(synth[:,:,150]))),cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.imshow(np.rot90(np.flipud(np.abs(synth[:,150,:]))),cmap='gray')\n",
        "  plt.text(128,10,contrast, color='r', horizontalalignment='center', verticalalignment='top', fontsize=30)\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.imshow(np.rot90(np.flipud(np.abs(synth[150,:,:]))),cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zvTVF48j5nD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Docker version for local execution\n",
        "\n",
        "The aim of this project is real life application and Google Colab is not how we aim to deploy this work. If you want to try the real life version of it on a machine that has [Docker](https://www.docker.com) installed, as well as a 11GB or larger GPU, please follow these steps:\n",
        "\n",
        "\n",
        "### Download data and code:\n",
        "This dataset is smaller than the one used in the Colab demo, and consists of five files:\n",
        "1. `ScanArchive_MRF.h5` <- contains MRF kspace data\n",
        "2. `ScanArchive_GRE.h5` <- contains calibration GRE kspace data (as well as the noise mesurements)\n",
        "3. `traj_grp16_inacc2.mat` <- contains the trajectory coordinates for the MRF (same as above)\n",
        "4. `subspace_basis_grp16.mat` <- contains the temporal basis components for the MRF (same as above)\n",
        "5. `python-sdk.tar` <- A Docker container provided by GE healthcare that can be used to read ScanArchive files.\n",
        "\n",
        "\n",
        "```\n",
        "git clone -q https://github.com/SophieSchau/MRF_demo_ISMRM2022.git\n",
        "cd MRF_demo_ISMRM2022\n",
        "mkdir data\n",
        "cd data\n",
        "wget -q -O data_docker.zip -L https://stanfordmedicine.box.com/shared/static/mvzz9lvpl8ixamesokypomyrnlx8pqs1\n",
        "unzip -q data_docker.zip\n",
        "cd ..\n",
        "mv data/MRF_Demo_ISMRM2022_Docker/* data/.\n",
        "mv data/python-sdk.tar src/00_io/python-sdk.tar\n",
        "mkdir result\n",
        "mkdir result/synth/\n",
        "export WORKDIR=`pwd`\n",
        "\n",
        "```\n",
        "### Build the first Docker container:\n",
        "Make sure you have Docker installed and running. Then run the following lines to build the data reader (Note, Docker containers can take a while to build, but you only need to build them once!):\n",
        "\n",
        "```\n",
        "cd ${WORKDIR}/src/00_io\n",
        "docker load -i python-sdk.tar # This loads the GE provided container to read ScanArchive files.\n",
        "docker build -t setsompop/scan_archive_io .\n",
        "```\n",
        "\n",
        "And run it with your local filesystem mounted so that it can read the ScanArchive files and write the numpy arrays that we will use for the rest of the pipeline.\n",
        "```\n",
        "docker run -v /:/mnt/:z setsompop/scan_archive_io \\\n",
        "             --scn /mnt/${WORKDIR}/data/ScanArchive_GRE.h5 \\\n",
        "             --ksp /mnt/${WORKDIR}/data/calib_raw.npy \\\n",
        "             --nse /mnt/${WORKDIR}/data/calib_nse.npy\n",
        "```\n",
        "\n",
        "We will use the same Docker container to read the MRF data (it can also be used to write Dicom images based on the metadata in the ScanArchive file, but we are skipping that for now!):\n",
        "\n",
        "```\n",
        "docker run -v /:/mnt/:z setsompop/scan_archive_io \\\n",
        "             --scn /mnt/${WORKDIR}/data/ScanArchive_MRF.h5 \\\n",
        "             --ksp /mnt/${WORKDIR}/data/mrf_raw.npy\n",
        "```\n",
        "### Matching the Colab tutorial\n",
        "The rest of the steps will follow the Colab tutorial. Just remember to add `/mnt/` and `${WORKDIR}` to your path so that Docker can find and write the files to your local filesystem! Next code blocks shows you how to build and run each step in the pipe (same as you did in the Colab notebook).\n",
        "\n",
        "#### Calibration:\n",
        "```\n",
        "cd ${WORKDIR}/src/01_calib\n",
        "docker build -t setsompop/calib .\n",
        "docker run --gpus all -v /:/mnt/:z setsompop/calib \\\n",
        "            --ksp /mnt/${WORKDIR}/data/calib_raw.npy \\\n",
        "            --nse /mnt/${WORKDIR}/data/calib_nse.npy \\\n",
        "            --ccm /mnt/${WORKDIR}/result/ccm.npy \\\n",
        "            --nrc 40 \\\n",
        "            --nsv 10 \n",
        "```\n",
        "\n",
        "#### MRF Reconstruction:\n",
        "```\n",
        "cd ${WORKDIR}/src/02_recon\n",
        "docker build -t setsompop/recon .\n",
        "docker run --gpus all -v /:/mnt/:z setsompop/recon \\\n",
        "            -c --phi /mnt/${WORKDIR}/data/subspace_basis_grp16.mat \\\n",
        "                   --trj /mnt/${WORKDIR}/data/traj_grp16_inacc2.mat \\\n",
        "                   --ksp /mnt/${WORKDIR}/data/mrf_raw.npy \\\n",
        "                   --ccm /mnt/${WORKDIR}/result/ccm.npy \\\n",
        "                   --res /mnt/${WORKDIR}/result/fast.npy \\\n",
        "                   --yfv False \\\n",
        "                   --mtx 256 --ptt 10 --rnk 3 --mit 40 --nco 3\n",
        "```\n",
        "\n",
        "#### MRF Synthesis:\n",
        "```\n",
        "cd ${WORKDIR}/src/03_synth\n",
        "docker build -t setsompop/synth .\n",
        "docker run --gpus all -v /:/mnt/:z setsompop/synth \\\n",
        "            --inp /mnt/${WORKDIR}/result/fast.npy \\\n",
        "                 --wgt /mnt/${WORKDIR}/src/03_synth/checkpoints/v1_InitCG/800_net_G.pth \\\n",
        "                 --sth /mnt/${WORKDIR}/result/synth \\\n",
        "                 --idx 0 1 2 3 4\n",
        "```"
      ],
      "metadata": {
        "id": "zyZxZ4P8CxD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W2JZnUU28m9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MRF_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP261u9X3LoX54yqC3FRBW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}